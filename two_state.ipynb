{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is for a 2 state markov chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD THE REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE THE GENERATOR AND DISCRIMINATOR MODEL ARCHITECHTURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(128, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Dense(256, use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Dense(20, activation='tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(256, input_shape=(20,)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Dense(128))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE THE LOSSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HERE I AM DEFININ THE OPTIMIZERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Generator optimizer\n",
    "generator_optimizer = tf.keras.optimizers.legacy.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Discriminator optimizer\n",
    "discriminator_optimizer = tf.keras.optimizers.legacy.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS THE TRAIN STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "@tf.function\n",
    "def train_step(real_sequences):\n",
    "\n",
    "    # Generate the latent noise\n",
    "    noise = tf.random.normal([real_sequences.shape[0], 100])\n",
    "\n",
    "    # Calculate the losses\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_sequences = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(real_sequences, training=True)\n",
    "        fake_output = discriminator(generated_sequences, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    # Calculate the gradients\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # Update the generator and discriminator\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of training epochs and batch size\n",
    "num_epochs = 500\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATING TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Define the training dataset\n",
    "# Replace `training_data` with your own training dataset of shape (num_samples, 20)\n",
    "training_data = np.random.randint(0, 10, size=(1000, 20))\n",
    "print(training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15 0.85]\n",
      " [0.4  0.6 ]]\n",
      "[[0.15 1.  ]\n",
      " [0.4  1.  ]]\n"
     ]
    }
   ],
   "source": [
    "#declare a transition matrix\n",
    "\n",
    "n = 2\n",
    "values = [[0.15 , 0.85], [0.4 , 0.6] ]\n",
    "\n",
    "matrix = np.array(values)\n",
    "\n",
    "print(matrix)\n",
    "\n",
    "cumm_matrix = np.array([[0.15 , 1], [0.4 , 1]])\n",
    "\n",
    "print(cumm_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63888\n",
      "136111\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "array = np.zeros(200000)  \n",
    "random_array = np.random.rand(199999)\n",
    "array[0] = 1\n",
    "cnt1 = 0\n",
    "cnt2 = 0\n",
    "\n",
    "for p in range(199999):\n",
    "    val = int(array[p])\n",
    "    x = random_array[p]\n",
    "\n",
    "    fin = 0\n",
    "    #for q in range(2):\n",
    "    if(val == -1):\n",
    "        val = 0\n",
    "        \n",
    "    if(x <= cumm_matrix[val][0]):\n",
    "        fin = -1\n",
    "        cnt1 = cnt1 + 1\n",
    "    else: \n",
    "        fin = 1\n",
    "        cnt2 = cnt2 + 1\n",
    "    \n",
    "\n",
    "    array[p+1] = fin\n",
    "\n",
    "\n",
    "print(cnt1)\n",
    "print(cnt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15073253 0.84926747]\n",
      " [0.39863053 0.60136947]]\n"
     ]
    }
   ],
   "source": [
    "zz = 0\n",
    "zo = 0\n",
    "oz = 0\n",
    "oo = 0\n",
    "\n",
    "\n",
    "for p in range(199999):\n",
    "    #noise = tf.random.normal([1, 100])\n",
    "    #generated_sequence = generator(noise, training=False).numpy().squeeze()\n",
    "\n",
    "    \n",
    "    if ((array[p] == -1) and (array[p+1] == -1)):\n",
    "        zz = zz + 1\n",
    "    if ((array[p] == -1) and (array[p+1] == 1)):\n",
    "        zo = zo + 1\n",
    "    if ((array[p] == 1) and (array[p+1] == -1)):\n",
    "        oz = oz + 1\n",
    "    if ((array[p] == 1) and (array[p+1] == 1)):\n",
    "        oo = oo + 1\n",
    "\n",
    "v1 = zz/(zz + zo)\n",
    "v2 = zo/(zz + zo)\n",
    "\n",
    "v3 = oz/(oz + oo)\n",
    "v4 = oo/(oz + oo)\n",
    "\n",
    "matrix = np.array([[v1 , v2],\n",
    "                   [v3,  v4]])\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = array.reshape(10000, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  1. ... -1.  1.  1.]\n",
      " [-1.  1. -1. ... -1. -1.  1.]\n",
      " [-1.  1. -1. ...  1.  1. -1.]\n",
      " ...\n",
      " [ 1. -1.  1. ... -1.  1. -1.]\n",
      " [ 1.  1.  1. ... -1.  1.  1.]\n",
      " [ 1.  1.  1. ...  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 20)\n"
     ]
    }
   ],
   "source": [
    "print(training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow Dataset from the training data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(training_data).shuffle(len(training_data)).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=TensorSpec(shape=(None, 20), dtype=tf.float64, name=None)>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIALIZE THE GENERATOR AND DISCRIMINATOR MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Generator and Discriminator models\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HERE THE TRAINING OCCURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function train_step at 0x000001FEB8F72F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function train_step at 0x000001FEB8F72F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91953\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py:5676: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/500 completed.\n",
      "Epoch 20/500 completed.\n",
      "Epoch 30/500 completed.\n",
      "Epoch 40/500 completed.\n",
      "Epoch 50/500 completed.\n",
      "Epoch 60/500 completed.\n",
      "Epoch 70/500 completed.\n",
      "Epoch 80/500 completed.\n",
      "Epoch 90/500 completed.\n",
      "Epoch 100/500 completed.\n",
      "Epoch 110/500 completed.\n",
      "Epoch 120/500 completed.\n",
      "Epoch 130/500 completed.\n",
      "Epoch 140/500 completed.\n",
      "Epoch 150/500 completed.\n",
      "Epoch 160/500 completed.\n",
      "Epoch 170/500 completed.\n",
      "Epoch 180/500 completed.\n",
      "Epoch 190/500 completed.\n",
      "Epoch 200/500 completed.\n",
      "Epoch 210/500 completed.\n",
      "Epoch 220/500 completed.\n",
      "Epoch 230/500 completed.\n",
      "Epoch 240/500 completed.\n",
      "Epoch 250/500 completed.\n",
      "Epoch 260/500 completed.\n",
      "Epoch 270/500 completed.\n",
      "Epoch 280/500 completed.\n",
      "Epoch 290/500 completed.\n",
      "Epoch 300/500 completed.\n",
      "Epoch 310/500 completed.\n",
      "Epoch 320/500 completed.\n",
      "Epoch 330/500 completed.\n",
      "Epoch 340/500 completed.\n",
      "Epoch 350/500 completed.\n",
      "Epoch 360/500 completed.\n",
      "Epoch 370/500 completed.\n",
      "Epoch 380/500 completed.\n",
      "Epoch 390/500 completed.\n",
      "Epoch 400/500 completed.\n",
      "Epoch 410/500 completed.\n",
      "Epoch 420/500 completed.\n",
      "Epoch 430/500 completed.\n",
      "Epoch 440/500 completed.\n",
      "Epoch 450/500 completed.\n",
      "Epoch 460/500 completed.\n",
      "Epoch 470/500 completed.\n",
      "Epoch 480/500 completed.\n",
      "Epoch 490/500 completed.\n",
      "Epoch 500/500 completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for sequences in train_dataset:\n",
    "        train_step(sequences)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sequence: [ 1.          1.          1.          1.          0.89844203 -1.\n",
      "  0.9999987   1.         -1.          0.99999416  1.          0.9989759\n",
      "  0.82211626  1.          1.         -0.9994055   0.9999714   0.99941415\n",
      "  0.99965197  0.95481765]\n"
     ]
    }
   ],
   "source": [
    "# Generate a sequence of length 20\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_sequence = generator(noise, training=False).numpy().squeeze()\n",
    "\n",
    "print(\"Generated Sequence:\", generated_sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATING SEQUENCES AND FINDING THE OUTPUT TRANSITION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = 0\n",
    "zo = 0\n",
    "oz = 0\n",
    "oo = 0\n",
    "\n",
    "\n",
    "for q in range(5000):\n",
    "    # LATENT VARIABLE\n",
    "    noise = tf.random.normal([1, 100])\n",
    "\n",
    "    # USING THE GENERATOR TO GENERATE\n",
    "    generated_sequence = generator(noise, training=False).numpy().squeeze()\n",
    "\n",
    "    # ROUNDING OFF\n",
    "    for p in range(20):\n",
    "        if(generated_sequence[p] < 0):\n",
    "            generated_sequence[p] = -1\n",
    "        else:\n",
    "            generated_sequence[p] = 1\n",
    "\n",
    "    for p in range(19):\n",
    "        if ((generated_sequence[p] == -1) and (generated_sequence[p+1] == -1)):\n",
    "            zz = zz + 1\n",
    "        if ((generated_sequence[p] == -1) and (generated_sequence[p+1] == 1)):\n",
    "            zo = zo + 1\n",
    "        if ((generated_sequence[p] == 1) and (generated_sequence[p+1] == -1)):\n",
    "            oz = oz + 1\n",
    "        if ((generated_sequence[p] == 1) and (generated_sequence[p+1] == 1)):\n",
    "            oo = oo + 1\n",
    "\n",
    "# CALCULATING THE TRANSITION MATRIX\n",
    "v1 = zz/(zz + zo)\n",
    "v2 = zo/(zz + zo)\n",
    "\n",
    "v3 = oz/(oz + oo)\n",
    "v4 = oo/(oz + oo)\n",
    "\n",
    "matrix = np.array([[v1 , v2],\n",
    "                   [v3,  v4]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(generated_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Transition matrix\n",
      "[[0.15 0.85]\n",
      " [0.4  0.6 ]]\n",
      "\n",
      "Generated Transition Matrix\n",
      "[[0.158  0.842 ]\n",
      " [0.3938 0.6062]]\n"
     ]
    }
   ],
   "source": [
    "values = np.array(values)\n",
    "\n",
    "print(\"Original Transition matrix\")\n",
    "print(np.array_str(values, precision=4, suppress_small=True))\n",
    "\n",
    "print(\"\\nGenerated Transition Matrix\")\n",
    "print(np.array_str(matrix, precision=4, suppress_small=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Transition Matrix:\n",
      "+---------+-----------+-----------+\n",
      "|         |   State 1 |   State 2 |\n",
      "+=========+===========+===========+\n",
      "| State 1 |      0.15 |      0.85 |\n",
      "+---------+-----------+-----------+\n",
      "| State 2 |      0.4  |      0.6  |\n",
      "+---------+-----------+-----------+\n",
      "\n",
      "Generated Transition Matrix:\n",
      "+---------+-----------+-----------+\n",
      "|         |   State 1 |   State 2 |\n",
      "+=========+===========+===========+\n",
      "| State 1 |   0.15804 |   0.84196 |\n",
      "+---------+-----------+-----------+\n",
      "| State 2 |   0.3938  |   0.6062  |\n",
      "+---------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "def print_matrix_as_table(matrix, matrix_name):\n",
    "    headers = [\"State {}\".format(i + 1) for i in range(matrix.shape[1])]\n",
    "    rows = [\"State {}\".format(i + 1) for i in range(matrix.shape[0])]\n",
    "    table = tabulate(matrix, headers=headers, showindex=rows, tablefmt=\"grid\")\n",
    "    print(f\"\\n{matrix_name}:\\n{table}\")\n",
    "\n",
    "# Print matrices as tables with labels\n",
    "print_matrix_as_table(values, \"Original Transition Matrix\")\n",
    "print_matrix_as_table(matrix, \"Generated Transition Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
