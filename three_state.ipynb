{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is for a 3 state markov chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE THE GENERATOR AND DISCRIMINATOR MODEL ARCHITECHTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256, input_shape=(100,), activation='relu'))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    # model.add(layers.Dense(1024, activation='relu'))\n",
    "    # model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(20, activation='tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256, input_shape=(20,), activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE THE LOSSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE THE OPTIMIZERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Generator optimizer\n",
    "generator_optimizer = tf.keras.optimizers.legacy.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Discriminator optimizer\n",
    "discriminator_optimizer = tf.keras.optimizers.legacy.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS THE TRAIN STEP FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "@tf.function\n",
    "def train_step(real_sequences):\n",
    "\n",
    "    # GENERATE LATENT VARIABLE\n",
    "    noise = tf.random.normal([real_sequences.shape[0], 100])\n",
    "\n",
    "    # CALCULATE THE LOSSES\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_sequences = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(real_sequences, training=True)\n",
    "        fake_output = discriminator(generated_sequences, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    # CALCULATE THE GRADIENTS\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # UPDATE THE GENERATOR AND DISCRIMINATOR\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of training epochs and batch size\n",
    "num_epochs = 500\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATE THE TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Define the training dataset\n",
    "# Replace `training_data` with your own training dataset of shape (num_samples, 20)\n",
    "training_data = np.random.randint(0, 10, size=(1000, 20))\n",
    "print(training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]]\n",
      "[[0 1 1]\n",
      " [0 0 1]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "#declare a transition matrix\n",
    "\n",
    "n = 3\n",
    "values = [[0, 1, 0], [0 , 0 , 1] , [1 , 0 , 0]]\n",
    "\n",
    "matrix = np.array(values)\n",
    "\n",
    "print(matrix)\n",
    "\n",
    "cumm_matrix = np.array([[0, 1, 1], [0, 0 ,1], [1, 1 , 1]])\n",
    "\n",
    "print(cumm_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "array = np.zeros(200000)  \n",
    "random_array = np.random.rand(199999)\n",
    "array[0] = 1\n",
    "cnt1 = 0\n",
    "cnt2 = 0\n",
    "\n",
    "for p in range(199999):\n",
    "    val = int(array[p])\n",
    "    x = random_array[p]\n",
    "\n",
    "    fin = 0\n",
    "\n",
    "    val = val + 1\n",
    "        \n",
    "    if(x <= cumm_matrix[val][0]):\n",
    "        fin = -1\n",
    "    elif(x <= cumm_matrix[val][1]): \n",
    "        fin = 0\n",
    "    else:\n",
    "        fin = 1\n",
    "\n",
    "    \n",
    "\n",
    "    array[p+1] = fin\n",
    "\n",
    "\n",
    "print(cnt1)\n",
    "print(cnt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "trans = np.zeros((3,3))\n",
    "\n",
    "for p in range(199999):\n",
    "    val1 = int(array[p]) + 1\n",
    "    val2 = int(array[p+1]) + 1\n",
    "\n",
    "    trans[val1][val2] = trans[val1][val2] + 1\n",
    "\n",
    "for p in range(3):\n",
    "    sum = 0\n",
    "    for q in range(3):\n",
    "        sum = sum + trans[p][q]\n",
    "\n",
    "    for q in range(3):\n",
    "        trans[p][q] = trans[p][q]/sum\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = array.reshape(10000, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  0. ...  0.  1. -1.]\n",
      " [ 0.  1. -1. ... -1.  0.  1.]\n",
      " [-1.  0.  1. ...  1. -1.  0.]\n",
      " ...\n",
      " [ 0.  1. -1. ... -1.  0.  1.]\n",
      " [-1.  0.  1. ...  1. -1.  0.]\n",
      " [ 1. -1.  0. ...  0.  1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 20)\n"
     ]
    }
   ],
   "source": [
    "print(training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow Dataset from the training data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(training_data).shuffle(len(training_data)).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=TensorSpec(shape=(None, 20), dtype=tf.float64, name=None)>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIALIZE THE GENERATOR AND DISCRIMINATOR MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Generator and Discriminator models\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HERE WE ARE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function train_step at 0x00000293DF8904C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function train_step at 0x00000293DF8904C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/500 completed.\n",
      "Epoch 20/500 completed.\n",
      "Epoch 30/500 completed.\n",
      "Epoch 40/500 completed.\n",
      "Epoch 50/500 completed.\n",
      "Epoch 60/500 completed.\n",
      "Epoch 70/500 completed.\n",
      "Epoch 80/500 completed.\n",
      "Epoch 90/500 completed.\n",
      "Epoch 100/500 completed.\n",
      "Epoch 110/500 completed.\n",
      "Epoch 120/500 completed.\n",
      "Epoch 130/500 completed.\n",
      "Epoch 140/500 completed.\n",
      "Epoch 150/500 completed.\n",
      "Epoch 160/500 completed.\n",
      "Epoch 170/500 completed.\n",
      "Epoch 180/500 completed.\n",
      "Epoch 190/500 completed.\n",
      "Epoch 200/500 completed.\n",
      "Epoch 210/500 completed.\n",
      "Epoch 220/500 completed.\n",
      "Epoch 230/500 completed.\n",
      "Epoch 240/500 completed.\n",
      "Epoch 250/500 completed.\n",
      "Epoch 260/500 completed.\n",
      "Epoch 270/500 completed.\n",
      "Epoch 280/500 completed.\n",
      "Epoch 290/500 completed.\n",
      "Epoch 300/500 completed.\n",
      "Epoch 310/500 completed.\n",
      "Epoch 320/500 completed.\n",
      "Epoch 330/500 completed.\n",
      "Epoch 340/500 completed.\n",
      "Epoch 350/500 completed.\n",
      "Epoch 360/500 completed.\n",
      "Epoch 370/500 completed.\n",
      "Epoch 380/500 completed.\n",
      "Epoch 390/500 completed.\n",
      "Epoch 400/500 completed.\n",
      "Epoch 410/500 completed.\n",
      "Epoch 420/500 completed.\n",
      "Epoch 430/500 completed.\n",
      "Epoch 440/500 completed.\n",
      "Epoch 450/500 completed.\n",
      "Epoch 460/500 completed.\n",
      "Epoch 470/500 completed.\n",
      "Epoch 480/500 completed.\n",
      "Epoch 490/500 completed.\n",
      "Epoch 500/500 completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for sequences in train_dataset:\n",
    "        train_step(sequences)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sequence: [-0.00296721  0.9984574  -0.99874353 -0.00550565  0.9994096  -0.9983182\n",
      "  0.01371708  0.9992208  -0.9988141  -0.00219619  0.99920315 -0.99919426\n",
      "  0.01000979  0.99931103 -0.9991055  -0.00120203  0.9992541  -0.9994422\n",
      " -0.00462942  0.9994129 ]\n"
     ]
    }
   ],
   "source": [
    "# Generate a sequence of length 20\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_sequence = generator(noise, training=False).numpy().squeeze()\n",
    "\n",
    "print(\"Generated Sequence:\", generated_sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATING SEQUENCES AND FINDING OUT THE OUTPUT TRANSITION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = np.zeros((3,3))\n",
    "\n",
    "for q in range(5000):\n",
    "    # LATENT VARIABLE\n",
    "    noise = tf.random.normal([1, 100])\n",
    "\n",
    "    # USING THE GENERATOR TO GENERATE\n",
    "    generated_sequence = generator(noise, training=False).numpy().squeeze()\n",
    "\n",
    "    # ROUNDING OFF\n",
    "    for p in range(20):\n",
    "        if(generated_sequence[p] < -0.66):\n",
    "            generated_sequence[p] = 0\n",
    "        elif(generated_sequence[p] < 0.33):\n",
    "            generated_sequence[p] = 1\n",
    "        else:\n",
    "            generated_sequence[p] = 2\n",
    "\n",
    "    for p in range(19):\n",
    "        final[int(generated_sequence[p])][int(generated_sequence[p+1])] += 1\n",
    "\n",
    "\n",
    "# CALCULATING THE TRANSITION MATRIX\n",
    "\n",
    "for p in range(3):\n",
    "    sum = 0\n",
    "    for q in range(3):\n",
    "        sum += final[p][q]\n",
    "\n",
    "    for q in range(3):\n",
    "        final[p][q] = final[p][q]/sum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Transition Matrix:\n",
      "+---------+-----------+-----------+-----------+\n",
      "|         |   State 1 |   State 2 |   State 3 |\n",
      "+=========+===========+===========+===========+\n",
      "| State 1 |         0 |         1 |         0 |\n",
      "+---------+-----------+-----------+-----------+\n",
      "| State 2 |         0 |         0 |         1 |\n",
      "+---------+-----------+-----------+-----------+\n",
      "| State 3 |         1 |         0 |         0 |\n",
      "+---------+-----------+-----------+-----------+\n",
      "\n",
      "Generated Transition Matrix:\n",
      "+---------+-----------+-----------+-----------+\n",
      "|         |   State 1 |   State 2 |   State 3 |\n",
      "+=========+===========+===========+===========+\n",
      "| State 1 |         0 |         1 |         0 |\n",
      "+---------+-----------+-----------+-----------+\n",
      "| State 2 |         0 |         0 |         1 |\n",
      "+---------+-----------+-----------+-----------+\n",
      "| State 3 |         1 |         0 |         0 |\n",
      "+---------+-----------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "def print_matrix_as_table(matrix, matrix_name):\n",
    "    headers = [\"State {}\".format(i + 1) for i in range(matrix.shape[1])]\n",
    "    rows = [\"State {}\".format(i + 1) for i in range(matrix.shape[0])]\n",
    "    table = tabulate(matrix, headers=headers, showindex=rows, tablefmt=\"grid\")\n",
    "    print(f\"\\n{matrix_name}:\\n{table}\")\n",
    "\n",
    "# Print matrices as tables with labels\n",
    "print_matrix_as_table(matrix, \"Original Transition Matrix\")\n",
    "print_matrix_as_table(final, \"Generated Transition Matrix\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
